\section{Optimistic Concurrency Control in Haswell} \label{sec:tm}

A simple mechanism that can be used to provide atomicity and isolation is
coarse-grained locks. This allows at least a limited amount of safe concurrency.
However, this is a pessimistic concurrency control protocol that targets
\textit{high-contention} workloads. Read accesses also need to incur the locking overhead
in this scheme.

For low-contention workloads (e.g, read-dominant workloads), an optimistic
concurrency control scheme generally provides better performance, as
transactions can be mostly executed in parallel, and only the few that conflict
will need to be aborted or retried. (Optimistic concurrency control mechanisms
generally still rely on locking to validate and commit speculatively executed
changes, but this critical section is relatively small.) This allows
non-conflicting accesses to avoid the overhead of locking, providing a
significant boost in throughput.

Originally proposed in the context of database transaction managers, OCC schemes
have also been applied to concurrent programming, in the form of transactional
memory. Such schemes expose very little of the concurrency control protocol to
the user. Instead of requiring the programmer to maintain complex locking code,
all of complexity of concurrency control is pushed lower in the programming
stack: to the language runtime layer (in the case of software transactional
memory schemes) or to the hardware layer (in the case of HTM schemes). The
programmer is presented only with the higher-level abstraction of
transactions. Transactional memory thus provides the additional benefit of
greatly simplifying concurrent programming.

Intel's Haswell processor provides a transactional memory abstraction at the
hardware level. Transactions are executed within a core's own L1 cache, and the
cache-coherence protocol is extended to check at commit time whether other cores
have committed conflicting writes. This implementation allows non-conflicting
transactions to elide locks entirely, serializing only conflicting transactions.

The Haswell processors implement HTM in the form of instruction set extensions
known as Transaction Synchronization Extensions (TSX). TSX supports two
interfaces \citep{tsx-intro}: \\

\begin{itemize} 
\item \textbf{Hardware Lock Elision (HLE):} \\ This is a backwards-compatible
  extension which allows specifying transaction regions via \texttt{XACQUIRE}
  and \texttt{XRELEASE} instruction prefixes. These prefixes are added to a set
  of existing atomic load/store instructions which are typically used to
  read/write locks. When the \texttt{XACQUIRE} prefix is included, the locking
  code is speculatively elided, and the transaction is checked for conflicts
  when the \texttt{XRELEASE} prefix next appears. If conflicts have occurred,
  transaction execution fails, and the TM implementation simply reverts to
  normal lock semantics: the transaction is re-executed, but this time using the
  normal load/store instructions. HLE is thus fully compatible with the
  conventional, lock-based programming model. \\
\item \textbf{Restricted Transactional Memory (RTM):} \\ This is a more flexible
  extension, albeit not a backward compatible one, which allows specification of
  transactions using new \texttt{XBEGIN}, \texttt{XEND}, and \texttt{XABORT}
  instructions. It allows the programmer to specify the fallback path for
  transaction failures. An example of a group sum operation using RTM interface
  is shown in \Cref{fig:rtm}.\\
\end{itemize}

\lstset{basicstyle=\ttfamily\fontsize{9}{10}\selectfont,
morekeywords={if,else,end}, numbers=left} \begin{figure}
    \parbox[t]{0.45\textwidth}{\lstinputlisting{figure/rtm.c}} \caption{Group
        sum operation using RTM interface. A mutex is obtained in fallback path
to avoid data race with the normal transaction execution path.} \label{fig:rtm}
\end{figure}

We evaluated both interfaces in this project. We implemented two different 
RTM schemes and one HLE scheme.
The \textit{simple RTM manager} nests the entire transaction execution within the RTM
instructions \texttt{XBEGIN} and \texttt{XEND} and grabs a mutex in the fallback path.
The more sophisticated \textit{RTM manager} only protects accesses to the lock table 
using the RTM instructions and the transaction execution itself is not in the critical 
path. We designed this scheme to perform well especially for large multi-key 
transactions.  
The \textit{HLE manager} is, by design, similar to the sophisticated RTM manager, except 
that it's fallback path involves execution of instructions while ignoring 
the \texttt{XACQUIRE} and \texttt{XRELEASE} prefixes.

When the read/write sets are static (known a priori), we prevent deadlocks in our
fine-grained schemes by enforcing an ordering in which a transaction may request 
locks. For dynamic read/write sets, we observed that using a simple coarse-grained 
lock delivered performance comparable to a more sophisticated fine-grained 
locking scheme with deadlock detection. We therefore use a coarse-grained locking
scheme in all the hardware-based concurrency control managers for handling
dynamic read/write sets effectively. This is a significant engineering benefit that 
we believe exemplifies the benefits of using HTM.  \\
